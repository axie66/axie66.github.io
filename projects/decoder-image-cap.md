---
layout: post
title: A Comparison of Decoder Models for Image Captioning
invisible: true
date: December 8, 2021
---

<img src='../assets/images/zebra_attention.png'/>

Inspired by recent advances in image captioning as well as in language modeling and language generation, we evaluate a variety of decoder architectures on the COCO Captions 2014 dataset, including Markov chains, recurrent neural networks, attention mechanisms, and transformers. Our proposed transformer models improve upon the baseline models by +4 BLEU-4 score and create feasible captions that approach those created by humans.

<div class='card clickable' onclick="location.href='../assets/docs/imgcap.pdf'">
    <div class='center text'>Full PDF</div>
</div>
<div class='card clickable' onclick="location.href='https://github.com/axie66/10701-project'">
    <div class='center text'>Code</div>
</div>